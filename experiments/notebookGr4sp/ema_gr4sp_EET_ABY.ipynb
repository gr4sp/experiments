{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup\n",
    "This analysis using ema is based on the work of Enayat A. Moallemi created on 22 May 2018 at the Fraunhofer ISI, Karlsruhe. In that instance, the analysis was done for the MATISSE model.\n",
    "This notebook present a first stage on a SA and UA. It is a screening process using the Elementary Effects Test (EET). For this, The EMA workbench is used with SAlib Morris sampler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:33.144535Z",
     "start_time": "2022-05-10T04:31:29.342620Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angel\\anaconda3\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py:21: UserWarning: ipyparallel not installed - IpyparalleEvaluator not available\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\anaconda3\\lib\\site-packages\\ema_workbench\\em_framework\\optimization.py:48: ImportWarning: platypus based optimization not available\n",
      "  warnings.warn(\"platypus based optimization not available\", ImportWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "By Angela M. Rojas A. <angelara@student.unimelb.edu.au>\n",
    "\n",
    "Created on 18 December 2019\n",
    "\n",
    "'''\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(r'C:\\Users\\angel\\Documents\\GitHub\\gr4sp\\experiments\\EMAworkbench')\n",
    "\n",
    "sys.path.append(r'C:\\Users\\angel\\Documents\\GitHub\\gr4sp\\experiments')\n",
    "\n",
    "#from ema_workbench.analysis.plotting_util import BOXPLOT, KDE, VIOLIN\n",
    "from ema_workbench.analysis.plotting import envelopes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from ema_workbench.analysis import prim\n",
    "#import pareto\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "includePlots = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the results\n",
    "These results are a tuple of one data frame with the changes on each input variable, and a dictionary with the outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.424209Z",
     "start_time": "2022-05-10T04:31:33.146418Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ema_workbench import load_results\n",
    "#AfterbaseYear resutls: last results Dec 02 2020\n",
    "results = load_results(r'C:/Users/angel/Documents/GitHub/gr4sp/experiments/simulationData/gr4sp_EET2020ABY-Dec-02.tar.gz')\n",
    "\n",
    "#Before and after base year results: last results on Jan 14 2021\n",
    "#results = load_results(r'C:/Users/angel/Documents/GitHub/gr4sp/experiments/simulationData/gr4sp_EETPast2021-Jan-14.tar.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.439933Z",
     "start_time": "2022-05-10T04:31:35.424976Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "experiments, outcomes = results\n",
    "outcomes['PrimarySpot-WholesalePriceYear'] = outcomes['wholesalePriceYear']\n",
    "\n",
    "\n",
    "# Create a temporary copy of dictionary, with Outcomes Year\n",
    "outcomesYear = dict(outcomes)\n",
    "\n",
    "keysToRemove = [] \n",
    "# Iterate over the temporary dictionary and delete corresponding key from original dictionary\n",
    "for (key, value) in outcomesYear.items() :\n",
    "    if 'Month' in key:\n",
    "        keysToRemove.append(key)\n",
    "        \n",
    "for k in keysToRemove:        \n",
    "    del outcomesYear[k]   \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.519090Z",
     "start_time": "2022-05-10T04:31:35.441928Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annualCpi</th>\n",
       "      <th>annualInflation</th>\n",
       "      <th>domesticConsumptionPercentage</th>\n",
       "      <th>generationRolloutPeriod</th>\n",
       "      <th>generatorRetirement</th>\n",
       "      <th>importPriceFactor</th>\n",
       "      <th>includePublicallyAnnouncedGen</th>\n",
       "      <th>learningCurve</th>\n",
       "      <th>nameplateCapacityChangeBattery</th>\n",
       "      <th>nameplateCapacityChangeBrownCoal</th>\n",
       "      <th>...</th>\n",
       "      <th>priceChangePercentageBrownCoal</th>\n",
       "      <th>priceChangePercentageCcgt</th>\n",
       "      <th>priceChangePercentageOcgt</th>\n",
       "      <th>priceChangePercentageSolar</th>\n",
       "      <th>priceChangePercentageWater</th>\n",
       "      <th>priceChangePercentageWind</th>\n",
       "      <th>scheduleMinCapMarketGen</th>\n",
       "      <th>semiScheduleMinCapMarketGen</th>\n",
       "      <th>technologicalImprovement</th>\n",
       "      <th>wholesaleTariffContribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.00000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.664714</td>\n",
       "      <td>2.709286</td>\n",
       "      <td>38.06400</td>\n",
       "      <td>4.950286</td>\n",
       "      <td>-0.032286</td>\n",
       "      <td>-0.351429</td>\n",
       "      <td>0.257000</td>\n",
       "      <td>7.248857</td>\n",
       "      <td>1.340000</td>\n",
       "      <td>-1.848571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617143</td>\n",
       "      <td>-0.060000</td>\n",
       "      <td>-0.634286</td>\n",
       "      <td>-0.985714</td>\n",
       "      <td>-0.574286</td>\n",
       "      <td>-0.622857</td>\n",
       "      <td>20.257143</td>\n",
       "      <td>14.847534</td>\n",
       "      <td>8.156143</td>\n",
       "      <td>26.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.445692</td>\n",
       "      <td>1.463340</td>\n",
       "      <td>12.66755</td>\n",
       "      <td>3.748614</td>\n",
       "      <td>3.643977</td>\n",
       "      <td>37.688490</td>\n",
       "      <td>0.437011</td>\n",
       "      <td>5.343287</td>\n",
       "      <td>35.933116</td>\n",
       "      <td>35.541008</td>\n",
       "      <td>...</td>\n",
       "      <td>35.866858</td>\n",
       "      <td>36.219345</td>\n",
       "      <td>35.419200</td>\n",
       "      <td>35.270470</td>\n",
       "      <td>36.450789</td>\n",
       "      <td>35.593240</td>\n",
       "      <td>7.227936</td>\n",
       "      <td>11.116881</td>\n",
       "      <td>5.479003</td>\n",
       "      <td>12.724411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>12.060000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>55.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>55.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         annualCpi  annualInflation  domesticConsumptionPercentage  \\\n",
       "count  7000.000000      7000.000000                     7000.00000   \n",
       "mean      2.664714         2.709286                       38.06400   \n",
       "std       1.445692         1.463340                       12.66755   \n",
       "min       1.000000         1.000000                       20.00000   \n",
       "25%       1.000000         2.000000                       34.00000   \n",
       "50%       3.000000         2.000000                       41.00000   \n",
       "75%       3.000000         3.000000                       55.00000   \n",
       "max       5.000000         5.000000                       55.00000   \n",
       "\n",
       "       generationRolloutPeriod  generatorRetirement  importPriceFactor  \\\n",
       "count              7000.000000          7000.000000        7000.000000   \n",
       "mean                  4.950286            -0.032286          -0.351429   \n",
       "std                   3.748614             3.643977          37.688490   \n",
       "min                   0.000000            -5.000000         -50.000000   \n",
       "25%                   0.000000            -5.000000         -50.000000   \n",
       "50%                   6.000000             1.000000         -10.000000   \n",
       "75%                  10.000000             5.000000          50.000000   \n",
       "max                  10.000000             5.000000          50.000000   \n",
       "\n",
       "       includePublicallyAnnouncedGen  learningCurve  \\\n",
       "count                    7000.000000    7000.000000   \n",
       "mean                        0.257000       7.248857   \n",
       "std                         0.437011       5.343287   \n",
       "min                         0.000000       0.000000   \n",
       "25%                         0.000000       0.000000   \n",
       "50%                         0.000000       6.000000   \n",
       "75%                         1.000000       9.000000   \n",
       "max                         1.000000      15.000000   \n",
       "\n",
       "       nameplateCapacityChangeBattery  nameplateCapacityChangeBrownCoal  ...  \\\n",
       "count                     7000.000000                       7000.000000  ...   \n",
       "mean                         1.340000                         -1.848571  ...   \n",
       "std                         35.933116                         35.541008  ...   \n",
       "min                        -50.000000                        -50.000000  ...   \n",
       "25%                        -10.000000                        -50.000000  ...   \n",
       "50%                         10.000000                        -10.000000  ...   \n",
       "75%                         50.000000                         10.000000  ...   \n",
       "max                         50.000000                         50.000000  ...   \n",
       "\n",
       "       priceChangePercentageBrownCoal  priceChangePercentageCcgt  \\\n",
       "count                     7000.000000                7000.000000   \n",
       "mean                         0.617143                  -0.060000   \n",
       "std                         35.866858                  36.219345   \n",
       "min                        -50.000000                 -50.000000   \n",
       "25%                        -10.000000                 -50.000000   \n",
       "50%                         10.000000                 -10.000000   \n",
       "75%                         10.000000                  50.000000   \n",
       "max                         50.000000                  50.000000   \n",
       "\n",
       "       priceChangePercentageOcgt  priceChangePercentageSolar  \\\n",
       "count                7000.000000                 7000.000000   \n",
       "mean                   -0.634286                   -0.985714   \n",
       "std                    35.419200                   35.270470   \n",
       "min                   -50.000000                  -50.000000   \n",
       "25%                   -50.000000                  -50.000000   \n",
       "50%                    10.000000                   10.000000   \n",
       "75%                    10.000000                   10.000000   \n",
       "max                    50.000000                   50.000000   \n",
       "\n",
       "       priceChangePercentageWater  priceChangePercentageWind  \\\n",
       "count                 7000.000000                7000.000000   \n",
       "mean                    -0.574286                  -0.622857   \n",
       "std                     36.450789                  35.593240   \n",
       "min                    -50.000000                 -50.000000   \n",
       "25%                    -50.000000                 -50.000000   \n",
       "50%                     10.000000                  10.000000   \n",
       "75%                     10.000000                  10.000000   \n",
       "max                     50.000000                  50.000000   \n",
       "\n",
       "       scheduleMinCapMarketGen  semiScheduleMinCapMarketGen  \\\n",
       "count              7000.000000                  7000.000000   \n",
       "mean                 20.257143                    14.847534   \n",
       "std                   7.227936                    11.116881   \n",
       "min                  10.000000                     0.100000   \n",
       "25%                  18.000000                     0.100000   \n",
       "50%                  22.000000                    12.060000   \n",
       "75%                  30.000000                    30.000000   \n",
       "max                  30.000000                    30.000000   \n",
       "\n",
       "       technologicalImprovement  wholesaleTariffContribution  \n",
       "count               7000.000000                  7000.000000  \n",
       "mean                   8.156143                    26.250000  \n",
       "std                    5.479003                    12.724411  \n",
       "min                    0.000000                    10.000000  \n",
       "25%                    6.000000                    10.000000  \n",
       "50%                    9.000000                    24.000000  \n",
       "75%                   15.000000                    31.000000  \n",
       "max                   15.000000                    45.000000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcomes are shown in year. Though another analysis can be done for monthly outcomes. \n",
    "In total (Jul 2020), there are 30 uncertain inputs (previous version 33 levers). \n",
    "Updated version (August 2020) included another input for the analysis. Therefore bringing the number of 31 inputs for the EET. The new input is to represent the changes on percentage of domestic consumption, as it was assumed to be an average of 30% during the whole simulation, but it is currently at 22% so this variability had to be checked. \n",
    "The Sep-Oct 2020 version has the same number of uncertainties, however another EET was run given that changes to nominal values and uncertanty ranges were made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.565132Z",
     "start_time": "2022-05-10T04:31:35.520281Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annualCpi: [1. 2. 3. 5.]\n",
      "annualInflation: [1. 2. 3. 5.]\n",
      "consumption: ['Central' 'Fast change' 'High DER' 'Slow change']\n",
      "domesticConsumptionPercentage: [20. 34. 41. 55.]\n",
      "energyEfficiency: ['Central' 'Slow change' 'Step change']\n",
      "generationRolloutPeriod: [ 0.  4.  6. 10.]\n",
      "generatorRetirement: [-5. -1.  1.  5.]\n",
      "importPriceFactor: [-50. -10.  10.  50.]\n",
      "includePublicallyAnnouncedGen: [0. 1.]\n",
      "learningCurve: [ 0.  6.  9. 15.]\n",
      "nameplateCapacityChangeBattery: [-50. -10.  10.  50.]\n",
      "nameplateCapacityChangeBrownCoal: [-50. -10.  10.  50.]\n",
      "nameplateCapacityChangeCcgt: [-50. -10.  10.  50.]\n",
      "nameplateCapacityChangeOcgt: [-50. -10.  10.  50.]\n",
      "nameplateCapacityChangeSolar: [-50. -10.  10.  50.]\n",
      "nameplateCapacityChangeWater: [-50. -10.  10.  50.]\n",
      "nameplateCapacityChangeWind: [-50. -10.  10.  50.]\n",
      "nonScheduleGenSpotMarket: ['none' 'primary' 'secondary']\n",
      "nonScheduleMinCapMarketGen: [ 0.1   6.06  9.04 15.  ]\n",
      "onsiteGeneration: ['Central' 'Slow change' 'Step change']\n",
      "priceChangePercentageBattery: [-50. -10.  10.  50.]\n",
      "priceChangePercentageBrownCoal: [-50. -10.  10.  50.]\n",
      "priceChangePercentageCcgt: [-50. -10.  10.  50.]\n",
      "priceChangePercentageOcgt: [-50. -10.  10.  50.]\n",
      "priceChangePercentageSolar: [-50. -10.  10.  50.]\n",
      "priceChangePercentageWater: [-50. -10.  10.  50.]\n",
      "priceChangePercentageWind: [-50. -10.  10.  50.]\n",
      "rooftopPV: ['both' 'business' 'residential']\n",
      "scheduleMinCapMarketGen: [10. 18. 22. 30.]\n",
      "semiScheduleGenSpotMarket: ['none' 'primary' 'secondary']\n",
      "semiScheduleMinCapMarketGen: [ 0.1  12.06 18.04 30.  ]\n",
      "solarUptake: ['Central' 'Fast change' 'High DER' 'Slow change']\n",
      "technologicalImprovement: [ 0.  6.  9. 15.]\n",
      "wholesaleTariffContribution: [10. 24. 31. 45.]\n"
     ]
    }
   ],
   "source": [
    "#outcomes Options: wholesalePriceYear, GHGYear, tariffsYear, primarySpotProductionYear,\n",
    "# secondarySpotProductionYear, offSpotProductionYear, rooftopPvProductionYear\n",
    "# numActorsYear\n",
    "outcomes_to_show =  ['consumptionYear', 'tariffsYear', 'wholesalePriceYear', 'GHGYear', \n",
    "                    'primarySpotProductionYear', 'secondarySpotProductionYear', \n",
    "                    'offSpotProductionYear', 'renewableContributionYear', 'rooftopPVProductionYear', \n",
    "                    'coalProductionYear', 'waterProductionYear', 'windProductionYear', 'gasProductionYear', \n",
    "                    'solarProductionYear', 'BatteryProductionYear', 'primaryUnmetDemandMwh', 'primaryUnmetDemandHours',\n",
    "                    'primaryUnmetDemandDays', 'primaryMaxUnmetDemandMwhPerHour', 'secondaryUnmetDemandMwh',\n",
    "                    'secondaryUnmetDemandHours', 'secondaryUnmetDemandDays','secondaryMaxUnmetDemandMwhPerHour']\n",
    "#outcomes_to_show = ['PrimarySpot-WholesalePriceYear']\n",
    "#outcomes_to_show = ['GHGYear', 'renewableContributionYear', 'wholesalePriceYear', 'tariffsYear']\n",
    "\n",
    "\n",
    "uncertainties = experiments.columns[:-3]\n",
    "#levers = ['rooftopPV', 'solarUptake']\n",
    "\n",
    "#from startYear\n",
    "startYear = 2019 # afterBaseYear\n",
    "startYearShift = (startYear - 1998)\n",
    "#startYearShift = (startYear - 1997) * 12\n",
    "#time = outcomes['TIMEYear'][0, startYearShift:-31]\n",
    "time = outcomes['TIMEYear'][0, startYearShift:]\n",
    "#index = pd.to_datetime(time, format = '%Y-%m-%d')\n",
    "index = pd.to_datetime(time, format = '%Y')\n",
    "\n",
    "for u in uncertainties:\n",
    "    var = experiments[u]\n",
    "    val = np.unique(var)\n",
    "    print(\"{}: {}\".format(u,val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EET\n",
    "To obtain the SALib results for each input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.797244Z",
     "start_time": "2022-05-10T04:31:35.566121Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jpype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15888/1348690894.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgr4spModelEET\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgetModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mema_workbench\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mem_framework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msalib_samplers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_SALib_problem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mema_workbench\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mem_framework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdetermine_parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mEMAworkbench\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mema_workbench\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIntegerParameter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRealParameter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCategoricalParameter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBooleanParameter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\gr4sp\\experiments\\gr4spModelEET.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'{}\\EMAworkbench'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mconnector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m from EMAworkbench.ema_workbench import (IntegerParameter, RealParameter, CategoricalParameter, BooleanParameter,\n",
      "\u001b[1;32m~\\Documents\\GitHub\\gr4sp\\experiments\\connector.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Import module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mjpype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Enable Java imports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjpype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jpype'"
     ]
    }
   ],
   "source": [
    "from gr4spModelEET import getModel\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "from ema_workbench.em_framework.samplers import determine_parameters\n",
    "from EMAworkbench.ema_workbench import (IntegerParameter, RealParameter, CategoricalParameter, BooleanParameter)\n",
    "\n",
    "model = getModel()\n",
    "UncertaintiesCategories = determine_parameters(model, 'uncertainties', union=False) \n",
    "problem = get_SALib_problem(UncertaintiesCategories)\n",
    "\n",
    "# Build input values as floats used for each lever/uncertainty to generate outcomes. Recover them from experiments variable\n",
    "X = None\n",
    "for u in uncertainties:\n",
    "    col_cat = None\n",
    "    # map category to an index\n",
    "    if isinstance(model.uncertainties[u], CategoricalParameter):\n",
    "        col_cat = [ float(model.uncertainties[u].index_for_cat(cat)) for cat in experiments[u] ]\n",
    "    else:\n",
    "        col_cat = [ float(cat) for cat in experiments[u] ]\n",
    "    \n",
    "    # Concatenate each lever/uncertainty\n",
    "    if X is None:\n",
    "        X=col_cat\n",
    "    else:\n",
    "        X = np.column_stack((X,col_cat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T08:53:58.295909Z",
     "start_time": "2020-07-03T08:53:58.289607Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Analysis of EET\n",
    "The analyse method from SALib helps in the identification of the key sensitivity measures: mu, mu*, and sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.801028Z",
     "start_time": "2022-05-10T04:31:35.801028Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from SALib.analyze import morris\n",
    "\n",
    "sigma_years_ooi = {}\n",
    "mu_star_years_ooi = {}\n",
    "for ooi in outcomes_to_show:\n",
    "    mu_star_years = pd.DataFrame([],columns=uncertainties)\n",
    "    sigma_years = pd.DataFrame([],columns=uncertainties)\n",
    "    for t in range(startYearShift, startYearShift + len(time)):\n",
    "        dataY = outcomes[ooi][:, t]\n",
    "        #change num_levels = p to do the analysis with p levels\n",
    "        Si = morris.analyze(problem, X, dataY, num_levels=6)\n",
    "        \n",
    "        morris_stats = {key: Si[key] for key in ['mu', 'mu_star', 'sigma',\n",
    "                                                           'mu_star_conf']}\n",
    "        morris_stats = pd.DataFrame(morris_stats, index=uncertainties)\n",
    "        \n",
    "        mu_star = pd.DataFrame([morris_stats['mu_star']],columns=uncertainties)                    \n",
    "        mu_star_years = mu_star_years.append(mu_star)\n",
    "        \n",
    "        sigma = pd.DataFrame([Si['sigma']], columns=uncertainties)\n",
    "        sigma_years = sigma_years.append(sigma)\n",
    "    \n",
    "    mu_star_years = mu_star_years.set_index(time)\n",
    "    sigma_years = sigma_years.set_index(time)\n",
    "    \n",
    "    #Filter columns for which all values are zero\n",
    "    mu_star_years = mu_star_years[mu_star_years.columns[(mu_star_years != 0).any()]]\n",
    "    sigma_years = sigma_years[sigma_years.columns[(sigma_years != 0).any()]]\n",
    "    \n",
    "    mu_star_years_ooi[ooi] = mu_star_years_ooi\n",
    "    sigma_years_ooi[ooi] = sigma_years\n",
    "    print(ooi)\n",
    "    if includePlots:\n",
    "        # Figure showing timeseries of mu* and sigma for each output and lever/uncertainty\n",
    "        if mu_star_years.empty is False:\n",
    "            plt_mu_star_years = mu_star_years.plot.line(title=ooi+' - mu_star', figsize=(30, 20), fontsize=20)\n",
    "            plt_mu_star_years.set_title(f\"{ooi} - mu_star\", fontsize=25)\n",
    "            plt.legend(fontsize=20)\n",
    "            plt_mu_star_years.get_figure().savefig('{}/fig{}.png'.format(r'C:\\\\Users\\\\angel\\\\Documents\\\\GitHub\\\\gr4sp\\\\experiments\\\\notebookGr4sp\\\\outputs\\\\figs', '_mu_star_years_%s'%(ooi)), \n",
    "                             dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        if sigma_years.empty is False:\n",
    "            plt_sigma_years = sigma_years.plot.line(title=ooi + ' - sigma', figsize=(30, 20), fontsize=20)\n",
    "            plt_sigma_years.set_title(f\"{ooi} - sigma\", fontsize=25)\n",
    "            plt.legend(fontsize=20)\n",
    "            plt_sigma_years.get_figure().savefig('{}/fig{}.png'.format(r'C:\\\\Users\\\\angel\\\\Documents\\\\GitHub\\\\gr4sp\\\\experiments\\\\notebookGr4sp\\\\outputs\\\\figs', '_sigma_years_%s'%(ooi)), \n",
    "                             dpi=300, bbox_inches='tight')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.802026Z",
     "start_time": "2022-05-10T04:31:35.802026Z"
    }
   },
   "outputs": [],
   "source": [
    "normalized_mu_star_years = {}\n",
    "for ooi in outcomes_to_show:\n",
    "    normalized_mu_star_years[ooi] = (mu_star_years_ooi[ooi] - mu_star_years_ooi[ooi].min().min())/(mu_star_years_ooi[ooi].max().max() - mu_star_years_ooi[ooi].min().min())\n",
    "    #normalized_sigma_years[ooi] = (sigma_years_ooi[ooi] - sigma_max_val_ooia_years_ooi[ooi].min())/sigma_max_val_ooi[ooi].max() - sigma_max_val_ooi[ooi].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.803025Z",
     "start_time": "2022-05-10T04:31:35.803025Z"
    },
    "cell_style": "center",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ooi in outcomes_to_show:\n",
    "    fig, ax = plt.subplots(figsize=(11, 9))\n",
    "    cmap = sns.color_palette(\"flare\", as_cmap=True)\n",
    "    \n",
    "\n",
    "    im = sns.heatmap(normalized_mu_star_years[ooi].T, cmap = cmap)\n",
    "    ax.set_title(ooi)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mu * per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.804021Z",
     "start_time": "2022-05-10T04:31:35.804021Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Save mu_star into EXCEL\n",
    "writer = pd.ExcelWriter('{}/EE_{}.xlsx'.format(r'C:\\\\Users\\\\angel\\\\Documents\\\\GitHub\\\\gr4sp\\\\experiments\\\\notebookGr4sp\\\\outputs\\\\data', '_mu_star'), engine='xlsxwriter')\n",
    "for ooi in outcomes_to_show:\n",
    "    \n",
    "    mu_star_years = mu_star_years_ooi[ooi]\n",
    "    if ooi == 'secondaryMaxUnmetDemandMwhPerHour':\n",
    "        ooi = 'secondMaxUnmetMwhPerHour'\n",
    "    mu_star_years.to_excel(writer, sheet_name=ooi)\n",
    "writer.save()\n",
    "\n",
    "#Save sigma into EXCEL\n",
    "writer = pd.ExcelWriter('{}/EE_{}.xlsx'.format(r'C:\\\\Users\\\\angel\\\\Documents\\\\GitHub\\\\gr4sp\\\\experiments\\\\notebookGr4sp\\\\outputs\\\\data', '_sigma'), engine='xlsxwriter')\n",
    "for ooi in outcomes_to_show:\n",
    "    sigma_years = sigma_years_ooi[ooi]\n",
    "    if ooi == 'secondaryMaxUnmetDemandMwhPerHour':\n",
    "        ooi = 'secondMaxUnmetMwhPerHour'\n",
    "    sigma_years.to_excel(writer, sheet_name=ooi)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average mu_star and sigma all years in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.805018Z",
     "start_time": "2022-05-10T04:31:35.805018Z"
    },
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "mu_star_average_ooi = {}\n",
    "mu_star_max_val_ooi = {}\n",
    "mu_star_median_ooi = {}\n",
    "sigma_average_ooi = {}\n",
    "sigma_max_val_ooi = {}\n",
    "sigma_median_ooi = {}\n",
    "\n",
    "for ooi in outcomes_to_show:\n",
    "    \n",
    "    mu_star_average_ooi[ooi] = mu_star_years_ooi[ooi].mean()    \n",
    "    mu_star_max_val_ooi[ooi] = mu_star_years_ooi[ooi].max()\n",
    "    mu_star_median_ooi[ooi] = mu_star_years_ooi[ooi].median()\n",
    "    sigma_average_ooi[ooi] = sigma_years_ooi[ooi].mean()\n",
    "    sigma_max_val_ooi[ooi] = sigma_years_ooi[ooi].max()\n",
    "    sigma_median_ooi[ooi] = sigma_years_ooi[ooi].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plots of mu_star vs sigma using max values\n",
    "Previous figures shown the changes of mu* and sigma over time for each lever/uncertainty and output. However, it is difficult to capture the most significant inputs, for this a mu* vs sigma plot (EET) is more\n",
    "appropriate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.806039Z",
     "start_time": "2022-05-10T04:31:35.806039Z"
    },
    "pycharm": {
     "name": "#%% \n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "#f = plt.figure(figsize=(20,30)) \n",
    "if includePlots:\n",
    "    for ooi in outcomes_to_show:\n",
    "\n",
    "        #Normalize values so all graphs are btw 0 and 1. Otherwise cannot use text coordinates below\n",
    "        normalized_mu_star = (mu_star_max_val_ooi[ooi] - mu_star_max_val_ooi[ooi].min())/(mu_star_max_val_ooi[ooi].max() - mu_star_max_val_ooi[ooi].min())\n",
    "        normalized_sigma = (sigma_max_val_ooi[ooi] - sigma_max_val_ooi[ooi].min())/(sigma_max_val_ooi[ooi].max() - sigma_max_val_ooi[ooi].min())\n",
    "\n",
    "        df_max = pd.concat({'mu_star_max': normalized_mu_star,'sigma_max': normalized_sigma}, axis=1)\n",
    "\n",
    "        f=plt.figure(figsize=(20,15))\n",
    "        f.suptitle(ooi)\n",
    "        \n",
    "\n",
    "\n",
    "        sns.scatterplot(x='mu_star_max',y='sigma_max', hue=df_max.index, data=df_max)\n",
    "\n",
    "        #df_max.plot.scatter(x='mu_star_max',y='sigma_max',c='DarkBlue')\n",
    "\n",
    "        #Add labels above points\n",
    "        for index, row in df_max.iterrows():\n",
    "                if row['mu_star_max'] <= 0.1 and row['sigma_max'] <= 0.1: continue\n",
    "                plt.annotate(index, # this is the text\n",
    "                             (row['mu_star_max'],row['sigma_max']), # this is the point to label\n",
    "                             textcoords=\"offset points\", # how to position the text\n",
    "                             xytext=(0,3), # distance from text to points (x,y)\n",
    "                             ha='left', # horizontal alignment can be left, right or center\n",
    "                             fontsize=12)  # font size\n",
    "\n",
    "\n",
    "        break\n",
    "        print(ooi)\n",
    "\n",
    "        plt.savefig('{}/fig{}.png'.format(r'C:\\\\Users\\\\angel\\\\Documents\\\\GitHub\\\\gr4sp\\\\experiments\\\\notebookGr4sp\\\\outputs\\\\figs', 'scatter_mu_star_sigmna_max_%s'%(ooi)),dpi=300, bbox_inches='tight')\n",
    "    \n",
    "# f.show()\n",
    "# f.clear()\n",
    "# plt.close(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset significant factors - normalisation max values\n",
    "Scatter plots of mu_star vs sigma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.807012Z",
     "start_time": "2022-05-10T04:31:35.807012Z"
    },
    "pycharm": {
     "name": "#%% \n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "#f = plt.figure(figsize=(20,30)) \n",
    "\n",
    "#bound used to filter INPUTS\n",
    "significance_bound = 0.3\n",
    "significant_inputs_max = set()\n",
    "significant_inputs_filter_max = {}\n",
    "for ooi in outcomes_to_show:\n",
    "    #Normalize values so all graphs are btw 0 and 1. Otherwise cannot use text coordinates below\n",
    "    normalized_mu_star = (mu_star_max_val_ooi[ooi] - mu_star_max_val_ooi[ooi].min())/(mu_star_max_val_ooi[ooi].max() - mu_star_max_val_ooi[ooi].min())\n",
    "    normalized_sigma = (sigma_max_val_ooi[ooi] - sigma_max_val_ooi[ooi].min())/(sigma_max_val_ooi[ooi].max() - sigma_max_val_ooi[ooi].min())\n",
    "    \n",
    "    #filter values\n",
    "    filter_mu_star = normalized_mu_star > significance_bound\n",
    "    filter_sigma = normalized_sigma > significance_bound\n",
    "    normalized_mu_star_filtered = normalized_mu_star[ filter_mu_star | filter_sigma ]\n",
    "    normalized_sigma_filtered = normalized_sigma[ filter_mu_star | filter_sigma ] \n",
    "    \n",
    "    #keep track significant inputs filter\n",
    "    significant_inputs_filter_max[ooi] = normalized_mu_star_filtered.index.values\n",
    "    for l in normalized_mu_star_filtered.index.values:\n",
    "        significant_inputs_max.add(l) \n",
    "    \n",
    "    #create dataframe     \n",
    "    df_max = pd.concat({'mu_star_max': normalized_mu_star_filtered,'sigma_max': normalized_sigma_filtered}, axis=1)\n",
    "    \n",
    "    #print significant indexes per ooi\n",
    "    print(ooi + ' - {}'.format(len(significant_inputs_filter_max[ooi])))\n",
    "    print(significant_inputs_filter_max[ooi])\n",
    "    \n",
    "    if includePlots:\n",
    "        #create figure\n",
    "        f=plt.figure()#figsize=(30,20))\n",
    "        f.suptitle(ooi, fontsize=20)\n",
    "\n",
    "        #ScatterPlot        \n",
    "        sns.scatterplot(x='mu_star_max',y='sigma_max', hue=df_max.index, data=df_max, legend=False)\n",
    "\n",
    "\n",
    "        #Add labels above points\n",
    "        for index, row in df_max.iterrows():\n",
    "                plt.annotate(index, # this is the text\n",
    "                             (row['mu_star_max'],row['sigma_max']), # this is the point to label\n",
    "                             textcoords=\"offset points\", # how to position the text\n",
    "                             xytext=(2,-2), # distance from text to points (x,y)\n",
    "                             ha='center', # horizontal alignment can be left, right or center\n",
    "                             fontsize=6)  # font size\n",
    "\n",
    "        \n",
    "\n",
    "    plt.savefig('{}/fig{}.png'.format(r'C:\\\\Users\\\\angel\\\\Documents\\\\GitHub\\\\gr4sp\\\\experiments\\\\notebookGr4sp\\\\outputs\\\\figs','scatter_mu_star_sigmna_max_%s_filtered'%(ooi)),dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "print(\"ALL significant inputs (%d)\"%len(significant_inputs_max))\n",
    "print(significant_inputs_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.808010Z",
     "start_time": "2022-05-10T04:31:35.808010Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalized_mu_star.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T02:37:10.398998Z",
     "start_time": "2020-10-02T02:37:10.394010Z"
    }
   },
   "source": [
    "### Scatter plots of mu_star vs sigma using mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.808010Z",
     "start_time": "2022-05-10T04:31:35.808010Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "#f = plt.figure(figsize=(20,30)) \n",
    "if includePlots:\n",
    "    for ooi in outcomes_to_show:\n",
    "\n",
    "        #Normalize values so all graphs are btw 0 and 1. Otherwise cannot use text coordinates below\n",
    "        normalized_mu_star = ( mu_star_median_ooi[ooi] -  mu_star_median_ooi[ooi].min())/( mu_star_median_ooi[ooi].max() -  mu_star_median_ooi[ooi].min())\n",
    "        normalized_sigma = (sigma_median_ooi[ooi] - sigma_median_ooi[ooi].min())/(sigma_median_ooi[ooi].max() - sigma_median_ooi[ooi].min())\n",
    "\n",
    "        df_max = pd.concat({'mu_star_median': normalized_mu_star,'sigma_median': normalized_sigma}, axis=1)\n",
    "\n",
    "        f=plt.figure(figsize=(20,15))\n",
    "        f.suptitle(ooi, fontsize=20)\n",
    "\n",
    "        sns.scatterplot(x='mu_star_median',y='sigma_median', hue=df_max.index, data=df_max)\n",
    "        #df_max.plot.scatter(x='mu_star_max',y='sigma_max',c='DarkBlue')\n",
    "\n",
    "        #Add labels above points\n",
    "        for index, row in df_max.iterrows():\n",
    "                if row['mu_star_median'] <= 0.1 and row['sigma_median'] <= 0.1: continue\n",
    "                plt.annotate(index, # this is the text\n",
    "                             (row['mu_star_median'],row['sigma_median']), # this is the point to label\n",
    "                             textcoords=\"offset points\", # how to position the text\n",
    "                             xytext=(0,3), # distance from text to points (x,y)\n",
    "                             ha='left', # horizontal alignment can be left, right or center\n",
    "                             fontsize=10)  # font size\n",
    "\n",
    "\n",
    "        \n",
    "        print(ooi)\n",
    "\n",
    "        plt.savefig('{}/fig{}.png'.format(r'C:\\\\Users\\\\angel\\\\Documents\\\\GitHub\\\\gr4sp\\\\experiments\\\\notebookGr4sp\\\\outputs\\\\figs', 'scatter_mu_star_sigmna_median_%s'%(ooi)),dpi=300, bbox_inches='tight')\n",
    "\n",
    "# f.show()\n",
    "# f.clear()\n",
    "# plt.close(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T07:53:50.811002Z",
     "start_time": "2020-07-04T07:53:50.803964Z"
    }
   },
   "source": [
    "### Subset significant factors - normalisation median values\n",
    "Scatter plots of mu_star vs sigma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.809007Z",
     "start_time": "2022-05-10T04:31:35.809007Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "#f = plt.figure(figsize=(20,30)) \n",
    "#bound used to filter INPUTS\n",
    "significance_bound = 0.2\n",
    "significant_inputs_median = set()\n",
    "significant_inputs_filter_median = {}\n",
    "normalized_mu_star_median_ooi = {}\n",
    "normalized_sigma_median_ooi = {}\n",
    "\n",
    "for ooi in outcomes_to_show:\n",
    "    #Normalize values so all graphs are btw 0 and 1. Otherwise cannot use text coordinates below\n",
    "    normalized_mu_star = (mu_star_median_ooi[ooi] - mu_star_median_ooi[ooi].min())/(mu_star_median_ooi[ooi].max() - mu_star_median_ooi[ooi].min())\n",
    "    normalized_sigma = (sigma_median_ooi[ooi] - sigma_median_ooi[ooi].min())/(sigma_median_ooi[ooi].max() - sigma_median_ooi[ooi].min())\n",
    "    normalized_mu_star_median_ooi[ooi] = normalized_mu_star\n",
    "    normalized_sigma_median_ooi[ooi] = normalized_sigma\n",
    "\n",
    "    \n",
    "    #filter values\n",
    "    filter_mu_star = normalized_mu_star > significance_bound\n",
    "    filter_sigma = normalized_sigma > significance_bound\n",
    "    normalized_mu_star_filtered = normalized_mu_star[ filter_mu_star | filter_sigma ]\n",
    "    normalized_sigma_filtered = normalized_sigma[ filter_mu_star | filter_sigma ] \n",
    "    \n",
    "    #keep track significant inputs filter\n",
    "    significant_inputs_filter_median[ooi] = normalized_mu_star_filtered.index.values\n",
    "    for l in normalized_mu_star_filtered.index.values:\n",
    "        significant_inputs_median.add(l) \n",
    "    \n",
    "    #create dataframe     \n",
    "    df_med = pd.concat({'mu_star_median': normalized_mu_star_filtered,'sigma_median': normalized_sigma_filtered}, axis=1)\n",
    "    df_med['Input Factors'] = np.arange(len(df_med))+1\n",
    "\n",
    "    \n",
    "    #print significant indexes per ooi\n",
    "    print(ooi + ' - {}'.format(len(significant_inputs_filter_median[ooi])))\n",
    "    print(significant_inputs_filter_median[ooi])\n",
    "\n",
    "#     if includePlots:\n",
    "#         #create figure\n",
    "#         f=plt.figure(figsize=(10,10))\n",
    "#         f.suptitle(ooi)\n",
    "        \n",
    "#         ax = sns.scatterplot(x='mu_star_median',y='sigma_median', hue=df_med.index, data=df_med, legend=True)\n",
    "\n",
    "#         # replace labels\n",
    "#         for t in ax.legend_.texts: \n",
    "#             t.set_text('$x_{%d}$ - %s'%(df_med.loc[t.get_text(),'Input Factors'],t.get_text()))\n",
    "#         plt.setp(ax.get_legend().get_texts(), fontsize='12') # for legend text\n",
    "\n",
    "#         #replace axes names\n",
    "#         ax.set_xlabel('$\\\\tilde{M}_{Norm}$', fontsize=16)\n",
    "#         ax.set_ylabel('$\\\\tilde{S}_{Norm}$', fontsize=16)\n",
    "\n",
    "        \n",
    "#         #Add labels above points\n",
    "#         for index, row in df_med.iterrows():\n",
    "#                 plt.annotate('$x_{%d}$'%df_med.loc[index,'Input Factors'], # this is the text\n",
    "#                              (row['mu_star_median'],row['sigma_median']), # this is the point to label\n",
    "#                              textcoords=\"offset points\", # how to position the text\n",
    "#                              xytext=(1,5), # distance from text to points (x,y)\n",
    "#                              ha='center', # horizontal alignment can be left, right or center\n",
    "#                              fontsize=14)  # font size\n",
    "#     plt.savefig('{}/fig{}.png'.format(r'C:\\\\Users\\\\angel\\\\Documents\\\\GitHub\\\\gr4sp\\\\experiments\\\\notebookGr4sp\\\\outputs\\\\figs','scatter_mu_star_sigma_median_%s_filtered'%(ooi)),dpi=300, bbox_inches='tight')\n",
    "    \n",
    "\n",
    "print(\"ALL significant inputs (%d)\"%len(significant_inputs_median))\n",
    "print(significant_inputs_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Union of significant factors using max and median values across years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.810004Z",
     "start_time": "2022-05-10T04:31:35.810004Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "significant_inputs = significant_inputs_max.union(significant_inputs_median)\n",
    "print(\"ALL significant inputs Union Max and Median analysis (%d)\"%len(significant_inputs))\n",
    "print(significant_inputs)\n",
    "\n",
    "significant_inputs = significant_inputs_max\n",
    "print(\"ALL significant inputs Max analysis (%d)\"%len(significant_inputs))\n",
    "print(significant_inputs)\n",
    "\n",
    "significant_inputs = significant_inputs_median\n",
    "print(\"ALL significant inputs Median analysis (%d)\"%len(significant_inputs))\n",
    "print(significant_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.811002Z",
     "start_time": "2022-05-10T04:31:35.811002Z"
    }
   },
   "outputs": [],
   "source": [
    "#save significant factors (max and median) into EXCEL\n",
    "writer = pd.ExcelWriter('{}/EE_{}.xlsx'.format(r'C:\\\\Users\\\\angel\\\\Documents\\\\GitHub\\\\gr4sp\\\\experiments\\\\notebookGr4sp\\\\outputs\\\\data', '_significant_max'), engine='xlsxwriter')\n",
    "significant_inputs_max_df = pd.DataFrame.from_dict(significant_inputs_filter_max,orient='index')\n",
    "significant_inputs_max_df.to_excel(writer, sheet_name='mu_sigma_max')\n",
    "writer.save()\n",
    "\n",
    "writer = pd.ExcelWriter('{}/EE_{}.xlsx'.format(r'C:\\\\Users\\\\angel\\\\Documents\\\\GitHub\\\\gr4sp\\\\experiments\\\\notebookGr4sp\\\\outputs\\\\data', '_significant_median'), engine='xlsxwriter')\n",
    "significant_inputs_filter_median_df = pd.DataFrame.from_dict(significant_inputs_filter_median,orient='index')\n",
    "significant_inputs_filter_median_df.to_excel(writer, sheet_name='mu_sigma_median')\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.812000Z",
     "start_time": "2022-05-10T04:31:35.812000Z"
    }
   },
   "outputs": [],
   "source": [
    "#save mu_star median values into excel\n",
    "writer = pd.ExcelWriter('{}/EE_{}.xlsx'.format(r'C:\\\\Users\\\\angel\\\\Documents\\\\GitHub\\\\gr4sp\\\\experiments\\\\notebookGr4sp\\\\outputs\\\\data', 'mu_star_median'), engine='xlsxwriter')\n",
    "significant_inputs_filter_median_df = pd.DataFrame.from_dict(normalized_mu_star_median_ooi,orient='columns')\n",
    "significant_inputs_filter_median_df.to_excel(writer, sheet_name='mu_star_median')\n",
    "writer.save()\n",
    "\n",
    "writer = pd.ExcelWriter('{}/EE_{}.xlsx'.format(r'C:\\\\Users\\\\angel\\\\Documents\\\\GitHub\\\\gr4sp\\\\experiments\\\\notebookGr4sp\\\\outputs\\\\data', 'sigma_median'), engine='xlsxwriter')\n",
    "significant_inputs_filter_median_df = pd.DataFrame.from_dict(normalized_sigma_median_ooi,orient='columns')\n",
    "significant_inputs_filter_median_df.to_excel(writer, sheet_name='sigma_median')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The big 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.813078Z",
     "start_time": "2022-05-10T04:31:35.813078Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "#f = plt.figure(figsize=(20,30)) \n",
    "includePlots = 1\n",
    "#bound used to filter INPUTS\n",
    "significance_bound = 0.2\n",
    "significant_inputs_median = set()\n",
    "significant_inputs_filter_median = {}\n",
    "normalized_mu_star_median_ooi = {}\n",
    "normalized_sigma_median_ooi = {}\n",
    "\n",
    "\n",
    "#create multi-figure\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 15),sharey=True)\n",
    "#fig.suptitle('Mu Star - Median')\n",
    "\n",
    "# OOI\n",
    "outcomes_to_show_4 = ['GHGYear', 'renewableContributionYear', 'wholesalePriceYear', 'tariffsYear']\n",
    "\n",
    "titles_ooi = {'GHGYear': 'GHGE', 'renewableContributionYear':'Renewable Energy Contribution', \n",
    "              'wholesalePriceYear': 'Wholesale Prices', 'tariffsYear':'Tariffs'  }\n",
    "\n",
    "#Gather items that will go into the legend\n",
    "\n",
    "for ooi in outcomes_to_show_4:\n",
    "    #Normalize values so all graphs are btw 0 and 1. Otherwise cannot use text coordinates below\n",
    "    normalized_mu_star = (mu_star_median_ooi[ooi] - mu_star_median_ooi[ooi].min())/(mu_star_median_ooi[ooi].max() - mu_star_median_ooi[ooi].min())\n",
    "    normalized_sigma = (sigma_median_ooi[ooi] - sigma_median_ooi[ooi].min())/(sigma_median_ooi[ooi].max() - sigma_median_ooi[ooi].min())\n",
    "    normalized_mu_star_median_ooi[ooi] = normalized_mu_star\n",
    "    normalized_sigma_median_ooi[ooi] = normalized_sigma\n",
    "\n",
    "    \n",
    "    #filter values\n",
    "    filter_mu_star = normalized_mu_star > significance_bound\n",
    "    filter_sigma = normalized_sigma > significance_bound\n",
    "    normalized_mu_star_filtered = normalized_mu_star[ filter_mu_star | filter_sigma ]\n",
    "    normalized_sigma_filtered = normalized_sigma[ filter_mu_star | filter_sigma ] \n",
    "    \n",
    "    #keep track significant inputs filter\n",
    "    significant_inputs_filter_median[ooi] = normalized_mu_star_filtered.index.values\n",
    "    for l in normalized_mu_star_filtered.index.values:\n",
    "        significant_inputs_median.add(l) \n",
    "        \n",
    "\n",
    "df_legend = pd.DataFrame.from_dict(significant_inputs_median)\n",
    "df_legend.columns = ['label']\n",
    "df_legend = df_legend.sort_values(by='label')\n",
    "df_legend['idx'] = np.arange(len(significant_inputs_median))+1\n",
    "        \n",
    "# Create Plots    \n",
    "for idx, ooi in enumerate(outcomes_to_show_4):\n",
    "\n",
    "    i = int(idx / 2)\n",
    "    j = int(idx % 2)\n",
    "\n",
    "    #Normalize values so all graphs are btw 0 and 1. Otherwise cannot use text coordinates below\n",
    "    normalized_mu_star = (mu_star_median_ooi[ooi] - mu_star_median_ooi[ooi].min())/(mu_star_median_ooi[ooi].max() - mu_star_median_ooi[ooi].min())\n",
    "    normalized_sigma = (sigma_median_ooi[ooi] - sigma_median_ooi[ooi].min())/(sigma_median_ooi[ooi].max() - sigma_median_ooi[ooi].min())\n",
    "    normalized_mu_star_median_ooi[ooi] = normalized_mu_star\n",
    "    normalized_sigma_median_ooi[ooi] = normalized_sigma\n",
    "\n",
    "    \n",
    "    #filter values\n",
    "    filter_mu_star = normalized_mu_star > significance_bound\n",
    "    filter_sigma = normalized_sigma > significance_bound\n",
    "    normalized_mu_star_filtered = normalized_mu_star[ filter_mu_star | filter_sigma ]\n",
    "    normalized_sigma_filtered = normalized_sigma[ filter_mu_star | filter_sigma ] \n",
    "    \n",
    "    #create dataframe     \n",
    "    df_med = pd.concat({'mu_star_median': normalized_mu_star_filtered,'sigma_median': normalized_sigma_filtered}, axis=1)\n",
    "    df_med['Input Factors'] = np.arange(len(df_med))+1\n",
    "\n",
    "    \n",
    "    #print significant indexes per ooi\n",
    "    print(ooi + ' - {}'.format(len(significant_inputs_filter_median[ooi])))\n",
    "    print(significant_inputs_filter_median[ooi])\n",
    "\n",
    "    if includePlots:\n",
    "        \n",
    "        print(i,j)\n",
    "        eet_plot = sns.scatterplot(x='mu_star_median',y='sigma_median', hue=df_med.index, data=df_med, \n",
    "                                   ax=axes[i,j], legend=False)\n",
    "        \n",
    "        axes[i,j].set_title(titles_ooi[ooi])\n",
    "        \n",
    "        eet_plot.set(xlabel='$\\\\tilde{M}_{Norm}$', ylabel='$\\\\tilde{S}_{Norm}$')\n",
    "        \n",
    "        #Add labels above points\n",
    "        for index, row in df_med.iterrows():\n",
    "                eet_plot.annotate('${%d}$'%df_legend.loc[df_legend['label']==index,'idx'].values, # this is the text\n",
    "                             (row['mu_star_median'],row['sigma_median']), # this is the point to label\n",
    "                             textcoords=\"offset points\", # how to position the text\n",
    "                             xytext=(1,5), # distance from text to points (x,y)\n",
    "                             ha='center', # horizontal alignment can be left, right or center\n",
    "                             fontsize=14)  # font size\n",
    "    \n",
    "if includePlots:\n",
    "    x_legend = '\\n'.join('$x_{%d}$ - %s'%(n,name) for n,name in zip(df_legend['idx'].values,df_legend['label'].values))\n",
    "\n",
    "    t = axes[0,0].text(.9,.35,x_legend,transform=axes[0,0].figure.transFigure)\n",
    "    fig.subplots_adjust(right=.85)\n",
    "    plt.savefig('{}/fig{}.png'.format(r'C:\\\\Users\\\\angel\\\\Documents\\\\GitHub\\\\gr4sp\\\\experiments\\\\notebookGr4sp\\\\outputs\\\\figs','scatter_mu_star_sigma_median_%s_filtered'%(ooi)),dpi=300, bbox_inches='tight')\n",
    "    \n",
    "\n",
    "print(\"ALL significant inputs (%d)\"%len(significant_inputs_median))\n",
    "print(significant_inputs_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram normalizsed $\\mu^*$ medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.813995Z",
     "start_time": "2022-05-10T04:31:35.813995Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "#f = plt.figure(figsize=(20,30)) \n",
    "\n",
    "#bound used to filter INPUTS\n",
    "significance_bound = 0.3\n",
    "significant_inputs_median = set()\n",
    "significant_inputs_filter_median = {}\n",
    "\n",
    "for ooi in outcomes_to_show:\n",
    "    #Normalize values so all graphs are btw 0 and 1. Otherwise cannot use text coordinates below\n",
    "    normalized_mu_star = (mu_star_median_ooi[ooi] - mu_star_median_ooi[ooi].min())/(mu_star_median_ooi[ooi].max() - mu_star_median_ooi[ooi].min())\n",
    "    normalized_sigma = (sigma_median_ooi[ooi] - sigma_median_ooi[ooi].min())/(sigma_median_ooi[ooi].max() - sigma_median_ooi[ooi].min())\n",
    "\n",
    "    \n",
    "    #create dataframe     \n",
    "    df_max = pd.concat({'mu_star_median': normalized_mu_star,'sigma_median': normalized_sigma}, axis=1)\n",
    "\n",
    "    \n",
    "    #create figure\n",
    "    f=plt.figure(figsize=(20,15))\n",
    "    f.suptitle(ooi)\n",
    "    \n",
    "    #ScatterPlot        \n",
    "\n",
    "    if includePlots:\n",
    "        eet_plot = sns.lineplot(data=df_max['mu_star_median'].sort_values(ascending=False), markers=True)\n",
    "\n",
    "        vertical_line = ''\n",
    "        for item in eet_plot.get_xticklabels():\n",
    "            item.set_rotation(90)\n",
    "            item.set_horizontalalignment('right')\n",
    "            item.set_fontsize(18)\n",
    "\n",
    "        eet_plot.axhline(significance_bound,ls='--',color='red')\n",
    "        \n",
    "        if True in (normalized_mu_star > significance_bound).value_counts():\n",
    "            vertical_line = (normalized_mu_star > significance_bound).value_counts()[True] - 1\n",
    "            eet_plot.axvline( vertical_line ,ls='--',color='red')\n",
    "\n",
    "\n",
    "        plt.savefig('{}/fig{}.png'.format(r'C:\\\\Users\\\\angel\\\\Documents\\\\GitHub\\\\gr4sp\\\\experiments\\\\notebookGr4sp\\\\outputs\\\\figs', 'ranking_mu_star_median_%s'%(ooi)),dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "# print(\"ALL significant inputs (%d)\"%len(significant_inputs_median))\n",
    "# print(significant_inputs_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.814991Z",
     "start_time": "2022-05-10T04:31:35.814991Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "#f = plt.figure(figsize=(20,30)) \n",
    "\n",
    "#bound used to filter INPUTS\n",
    "significance_bound = 0.3\n",
    "significant_inputs_median = set()\n",
    "significant_inputs_filter_median = {}\n",
    "outcomes_to_show = ['GHGYear', 'renewableContributionYear', 'wholesalePriceYear', 'tariffsYear']\n",
    "\n",
    "\n",
    "\n",
    "#create multi-figure\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 15),sharey=True)\n",
    "#fig.suptitle('Mu Star - Median')\n",
    "\n",
    "# OOI\n",
    "\n",
    "titles_ooi = {'GHGYear': 'GHGE', 'renewableContributionYear':'Renewable Energy Contribution', \n",
    "              'wholesalePriceYear': 'Wholesale Prices', 'tariffsYear':'Tariffs'  }\n",
    "\n",
    "for idx, ooi in enumerate(outcomes_to_show):\n",
    "    \n",
    "    i = int(idx / 2)\n",
    "    j = int(idx % 2)\n",
    "\n",
    "    #Normalize values so all graphs are btw 0 and 1. Otherwise cannot use text coordinates below\n",
    "    normalized_mu_star = (mu_star_median_ooi[ooi] - mu_star_median_ooi[ooi].min())/(mu_star_median_ooi[ooi].max() - mu_star_median_ooi[ooi].min())\n",
    "    normalized_sigma = (sigma_median_ooi[ooi] - sigma_median_ooi[ooi].min())/(sigma_median_ooi[ooi].max() - sigma_median_ooi[ooi].min())\n",
    "\n",
    "    \n",
    "    #create dataframe     \n",
    "    df_max = pd.concat({'M_norm': normalized_mu_star,'sigma_median': normalized_sigma}, axis=1)\n",
    "    df_max['Input Factors'] = np.arange(len(df_max))+1\n",
    "\n",
    "    if includePlots:\n",
    "        print(i,j)\n",
    "        eet_plot = sns.barplot(x='Input Factors',y='M_norm',data=df_max, ax=axes[i,j])\n",
    "        #        eet_plot = sns.lineplot(data=df_max['mu_star_median'].sort_values(ascending=False), markers=True, ax=axes[i,j])\n",
    "\n",
    "        axes[i,j].set_title(titles_ooi[ooi])\n",
    "\n",
    "        \n",
    "        eet_plot.set(xlabel='', ylabel='$\\\\tilde{M}_{Norm}$')\n",
    "        vertical_line = ''\n",
    "        for item in eet_plot.get_xticklabels():\n",
    "            item.set_rotation(90)\n",
    "            item.set_horizontalalignment('center')\n",
    "            item.set_fontsize(12)\n",
    "         \n",
    "        #labels = df_max.sort_values('mu_star_median',ascending=False)['id'].values\n",
    "        labels = df_max['Input Factors'].values\n",
    "        \n",
    "        labels = ['$x_{%d}$'%n for n in labels]\n",
    "\n",
    "        axes[i,j].set_xticklabels(labels)\n",
    "\n",
    "        eet_plot.axhline(significance_bound,ls='--',color='red')\n",
    "        \n",
    "#         if True in (normalized_mu_star > significance_bound).value_counts():\n",
    "#             vertical_line = (normalized_mu_star > significance_bound).value_counts()[True] - 1\n",
    "#             eet_plot.axvline( vertical_line ,ls='--',color='red')\n",
    "\n",
    "\n",
    "if includePlots:\n",
    "    #fig.legend(handles, labels, loc='upper center')\n",
    "    # Create the legend\n",
    "#     fig.legend([],     # The line objects\n",
    "#                labels=df_max.index.values,   # The labels for each line\n",
    "#                loc=\"center right\",   # Position of legend\n",
    "#                borderaxespad=0.1,    # Small spacing around legend box\n",
    "#                title=\"Legend Title\"  # Title for the legend\n",
    "#                )\n",
    "    x_legend = '\\n'.join('$x_{%d}$ - %s'%(n,name) for n,name in zip(df_max['Input Factors'].values,df_max.index.values))\n",
    "\n",
    "    t = axes[0,0].text(.9,.35,x_legend,transform=axes[0,0].figure.transFigure)\n",
    "    fig.subplots_adjust(right=.85)\n",
    "    \n",
    "\n",
    "    plt.savefig('{}/fig{}.png'.format(r'C:\\\\Users\\\\angel\\\\Documents\\\\GitHub\\\\gr4sp\\\\experiments\\\\notebookGr4sp\\\\outputs\\\\figs', 'ranking_mu_star_median_subplots'),dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T04:31:35.815991Z",
     "start_time": "2022-05-10T04:31:35.815991Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# index = pd.to_datetime(time, format = '%Y')\n",
    "\n",
    "# for ooi in outcomes_to_show:\n",
    "#     data = outcomes[ooi][:, startYearShift:]\n",
    "    \n",
    "   \n",
    "#     for u in uncertainties:\n",
    "#         dfBoxPlot = pd.DataFrame(index = index, data = data.T,columns=[ experiments[u] ])\n",
    "#         dfMeltdfBoxPlot = pd.melt(dfBoxPlot)\n",
    "#         #dfMeltdfBoxPlot.rename(columns={\"value\":ooi})\n",
    "    \n",
    "#         ax = dfMeltdfBoxPlot.boxplot(by=u, meanline=True, showmeans=False, showcaps=True, \n",
    "#                         showbox=True, showfliers=False, return_type='axes', figsize=(15, 10))\n",
    "        \n",
    "        \n",
    "#         plt.savefig('{}/fig{}.png'.format(r'C:\\\\Users\\\\angel\\\\Documents\\\\GitHub\\\\gr4sp\\\\experiments\\\\notebookGr4sp\\\\outputs\\\\figs', '_eet_boxplots_%s_%s'%(ooi,u)), \n",
    "#                      dpi=300, bbox_inches='tight')\n",
    "        \n",
    "       \n",
    "#         plt.show()\n",
    "#         plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "536.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1541px",
    "right": "20px",
    "top": "153px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
